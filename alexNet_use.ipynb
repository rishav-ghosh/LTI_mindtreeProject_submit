{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020d3c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1e6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Users/rishavghosh/Desktop/python/Oasis_dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc6cc017",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=models.AlexNet_Weights.IMAGENET1K_V1\n",
    "transform = weights.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3b1bf64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[224]\n",
       "    resize_size=[256]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BILINEAR\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61030e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Mild Dementia', 'Moderate Dementia', 'Non Demented', 'Very mild Dementia']\n"
     ]
    }
   ],
   "source": [
    "full_dataset = datasets.ImageFolder(DATA_DIR, transform=transform)\n",
    "print(\"Classes:\", full_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9f818fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 96336\n",
      "Test size: 24085\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Test size:\", len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81f8c639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts: {'Mild Dementia': 11212, 'Moderate Dementia': 5543, 'Non Demented': 61488, 'Very mild Dementia': 18093}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Extract labels from train dataset\n",
    "train_targets = [full_dataset.samples[i][1] for i in train_dataset.indices]\n",
    "class_counts = np.bincount(train_targets)\n",
    "\n",
    "print(\"Train class counts:\", dict(zip(full_dataset.classes, class_counts)))\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = 1. / torch.tensor(class_counts, dtype=torch.float)\n",
    "sample_weights = [class_weights[label] for label in train_targets]\n",
    "\n",
    "# Sampler for balanced training\n",
    "train_sampler = WeightedRandomSampler(weights=sample_weights,\n",
    "                                      num_samples=len(sample_weights),\n",
    "                                      replacement=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5886049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7890849",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcd675cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.alexnet(weights=weights)\n",
    "# Replace the classifier’s last layer\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 4)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea70fc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "AlexNet (AlexNet)                        [32, 3, 224, 224]    [32, 4]              --                   True\n",
       "├─Sequential (features)                  [32, 3, 224, 224]    [32, 256, 6, 6]      --                   True\n",
       "│    └─Conv2d (0)                        [32, 3, 224, 224]    [32, 64, 55, 55]     23,296               True\n",
       "│    └─ReLU (1)                          [32, 64, 55, 55]     [32, 64, 55, 55]     --                   --\n",
       "│    └─MaxPool2d (2)                     [32, 64, 55, 55]     [32, 64, 27, 27]     --                   --\n",
       "│    └─Conv2d (3)                        [32, 64, 27, 27]     [32, 192, 27, 27]    307,392              True\n",
       "│    └─ReLU (4)                          [32, 192, 27, 27]    [32, 192, 27, 27]    --                   --\n",
       "│    └─MaxPool2d (5)                     [32, 192, 27, 27]    [32, 192, 13, 13]    --                   --\n",
       "│    └─Conv2d (6)                        [32, 192, 13, 13]    [32, 384, 13, 13]    663,936              True\n",
       "│    └─ReLU (7)                          [32, 384, 13, 13]    [32, 384, 13, 13]    --                   --\n",
       "│    └─Conv2d (8)                        [32, 384, 13, 13]    [32, 256, 13, 13]    884,992              True\n",
       "│    └─ReLU (9)                          [32, 256, 13, 13]    [32, 256, 13, 13]    --                   --\n",
       "│    └─Conv2d (10)                       [32, 256, 13, 13]    [32, 256, 13, 13]    590,080              True\n",
       "│    └─ReLU (11)                         [32, 256, 13, 13]    [32, 256, 13, 13]    --                   --\n",
       "│    └─MaxPool2d (12)                    [32, 256, 13, 13]    [32, 256, 6, 6]      --                   --\n",
       "├─AdaptiveAvgPool2d (avgpool)            [32, 256, 6, 6]      [32, 256, 6, 6]      --                   --\n",
       "├─Sequential (classifier)                [32, 9216]           [32, 4]              --                   True\n",
       "│    └─Dropout (0)                       [32, 9216]           [32, 9216]           --                   --\n",
       "│    └─Linear (1)                        [32, 9216]           [32, 4096]           37,752,832           True\n",
       "│    └─ReLU (2)                          [32, 4096]           [32, 4096]           --                   --\n",
       "│    └─Dropout (3)                       [32, 4096]           [32, 4096]           --                   --\n",
       "│    └─Linear (4)                        [32, 4096]           [32, 4096]           16,781,312           True\n",
       "│    └─ReLU (5)                          [32, 4096]           [32, 4096]           --                   --\n",
       "│    └─Linear (6)                        [32, 4096]           [32, 4]              16,388               True\n",
       "========================================================================================================================\n",
       "Total params: 57,020,228\n",
       "Trainable params: 57,020,228\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 22.74\n",
       "========================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 126.26\n",
       "Params size (MB): 228.08\n",
       "Estimated Total Size (MB): 373.60\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model = model,\n",
    "        input_size = (32, 3, 224, 224),\n",
    "        col_names = [\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width = 20,\n",
    "        row_settings = [\"var_names\"]\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5612fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57886ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False \n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf28dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.classifier.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a05c3013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Time: 666.53s\n",
      "  Train Loss: 0.5766, Train Acc: 0.7584\n",
      "  Val Loss  : 0.4024, Val Acc  : 0.8117\n",
      "Epoch 2/10, Time: 670.48s\n",
      "  Train Loss: 0.3847, Train Acc: 0.8446\n",
      "  Val Loss  : 0.3010, Val Acc  : 0.8659\n",
      "Epoch 3/10, Time: 700.27s\n",
      "  Train Loss: 0.3085, Train Acc: 0.8790\n",
      "  Val Loss  : 0.2618, Val Acc  : 0.8857\n",
      "Epoch 4/10, Time: 726.02s\n",
      "  Train Loss: 0.2689, Train Acc: 0.8967\n",
      "  Val Loss  : 0.2403, Val Acc  : 0.8929\n",
      "Epoch 5/10, Time: 724.40s\n",
      "  Train Loss: 0.2403, Train Acc: 0.9083\n",
      "  Val Loss  : 0.2298, Val Acc  : 0.9028\n",
      "Epoch 6/10, Time: 712.95s\n",
      "  Train Loss: 0.2149, Train Acc: 0.9190\n",
      "  Val Loss  : 0.2140, Val Acc  : 0.9048\n",
      "Epoch 7/10, Time: 713.35s\n",
      "  Train Loss: 0.2014, Train Acc: 0.9255\n",
      "  Val Loss  : 0.1448, Val Acc  : 0.9354\n",
      "Epoch 8/10, Time: 714.61s\n",
      "  Train Loss: 0.1937, Train Acc: 0.9283\n",
      "  Val Loss  : 0.1430, Val Acc  : 0.9367\n",
      "Epoch 9/10, Time: 697.45s\n",
      "  Train Loss: 0.1768, Train Acc: 0.9355\n",
      "  Val Loss  : 0.1607, Val Acc  : 0.9293\n",
      "Epoch 10/10, Time: 720.76s\n",
      "  Train Loss: 0.1707, Train Acc: 0.9387\n",
      "  Val Loss  : 0.1363, Val Acc  : 0.9435\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion, device)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Time: {elapsed:.2f}s\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"  Val Loss  : {val_loss:.4f}, Val Acc  : {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c767591",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'alexNet_alzheimers_extraData.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d498a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
